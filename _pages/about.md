---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am an Embodied AI student researcher currently working at Northeastern University (Foshan), under the supervision of Professor [Xiaoguang Ma](http://www.ise.neu.edu.cn/2021/0909/c6131a202809/page.htm). Recently, I am focusing on research in Agentic UAVs. Prior to this, I received my Master's degree in Electronic Information from Zhejiang University of Technology in June 2024, where my work was dedicated to developing visual Simultaneous Localization and Mapping (vSLAM) algorithms for ground mobile robots to achieve visual navigation in dynamic scenes.

More about me: [Email](dxy1999ai@163.com) / [Google Scholar](https://scholar.google.com/citations?user=YourProfileID) / [Github](https://github.com/YourUsername) / [Curriculum Vitae](https://example.com/your-cv.pdf)

Feel free to contact me by email if you are interested in discussing or collaborating with me.

# ğŸ’» Research Vision
My current research focuses on developing self-improving / self-evolving embodied navigation agents, and exploring their applications in aerial and ground robots. In the long run, my research vision is to build an embodied agent that can autonomously perceive, make decisions, and learn continuously like humans. To achieve this, I primarily focus on:
1. Language-driven visual navigation (e.g., VLN and ObjectNav).
2. Large foundation models (e.g., LLMs and VLMs) and their training techniques.
4. Lifelong learning of LLM / VLM-powered agents.
5. Vision-Language-Action models and their applications.

# ğŸ”¥ News
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ One paper was accepted to Chinese Journal of Sensors and Actuators about visual SLAM! 
- *2024.06*: &nbsp;ğŸ‰ğŸ‰ I obtained my Master's degree from Zhejiang University of Technology!
- *2024.05*: &nbsp;ğŸ‰ğŸ‰ I joined Professor Xiaoguang Ma's laboratory!
- *2024.03*: &nbsp;ğŸ‰ğŸ‰ One paper was accepted to IEEE DDCLS 2024 about visual SLAM! 
- *2023.05: &nbsp;ğŸ‰ğŸ‰ I gave an oral presentation on visual SLAM at IEEE DDCLS 2023!

# ğŸ“ Publications (co-first authors: *, corresponding authors: #)

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2025</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models](https://arxiv.org/abs/2507.13152)

**Xiangyu Dong**, Haoran Zhao, Jiang Gao, Haozhou Li, Xiaoguang Ma, Yaoming Zhou, Fuhai Chen, Juan Liu

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- We drew inspiration from the evolution capabilities of natural agents, and proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the ability to continuously evolve during testing. To the best of our knowledge, it was the first time that an multimodal LLM-powered self-evolving VLN framework was proposed.
</div>
</div>

- Boosting LLM-Powered Agentic UAVs via Reflective Self-Learning for Language-Goal Aerial Navigation, Haoyu Tong, __Xiangyu Dong__, Xiaoguang Ma #, Submitted to ICRA 2026.
-  "MR-VLN: Towards Continual Vision-and-Language Navigation via Multimodal Memory and Retrieval",Haozhou Li, __Xiangyu Dong__, Xiaoguang Ma #, Submitted to ICRA 2026.
-  "PM-Nav: Prior-Map Guided Instruction Navigation in Public Buildings",Jiang Gao *, __Xiangyu Dong *__, Haozhou Li, Haoran Zhao, Yaoming Zhou, Xiaoguang Ma #, Submitted to AAAI 2026.
-  "Dual-memory Visual Question Answering Continual Learning", Fuhai Chen #, __Xiangyu Dong__, Xiaoguang Ma,Submitted to AAAI 2026. 
-"SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models",  __Xiangyu Dong *__, Haoran Zhao *, Jiang Gao, Haozhou Li, Xiaoguang Ma #, Yaoming Zhou #, Fuhai Chen, Juan Liu, Submitted to AAAI 2026.
-  "SEMA-VLN: A Self-Evolving Multi-Agent Vision-and-Language Navigation Framework Based on Foundation Models", __Xiangyu Dong__, Jiang Gao, Haozhou Li, Xiaoguang Ma #, Wei Meng, Zhengtao Hu,IEEE RAL, 2025, under review.

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
